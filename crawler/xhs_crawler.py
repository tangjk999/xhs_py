import requests
import json
import time
import random
from bs4 import BeautifulSoup
from selenium import webdriver
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from fake_useragent import UserAgent
import pandas as pd
from datetime import datetime
import os
import sys
import subprocess

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config

class XHSCrawler:
    def __init__(self):
        self.config = Config()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': self.config.USER_AGENT,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        self.driver = None
        
    def _get_chrome_version(self):
        """è·å–Chromeæµè§ˆå™¨ç‰ˆæœ¬"""
        try:
            result = subprocess.run(['/Applications/Google Chrome.app/Contents/MacOS/Google Chrome', '--version'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                version_str = result.stdout.strip()
                # æå–ç‰ˆæœ¬å·
                import re
                match = re.search(r'(\d+)\.(\d+)\.(\d+)\.(\d+)', version_str)
                if match:
                    return f"{match.group(1)}.{match.group(2)}.{match.group(3)}.{match.group(4)}"
        except Exception as e:
            print(f"è·å–Chromeç‰ˆæœ¬å¤±è´¥: {e}")
        return None
    
    def _force_update_chromedriver(self):
        """å¼ºåˆ¶æ›´æ–°ChromeDriveråˆ°åŒ¹é…ç‰ˆæœ¬"""
        try:
            chrome_version = self._get_chrome_version()
            if not chrome_version:
                print("æ— æ³•è·å–Chromeç‰ˆæœ¬")
                return False
            
            print(f"Chromeç‰ˆæœ¬: {chrome_version}")
            
            # å°è¯•ä½¿ç”¨webdriver-managerå¼ºåˆ¶æ›´æ–°
            try:
                from webdriver_manager.chrome import ChromeDriverManager
                driver_path = ChromeDriverManager().install()
                print(f"ChromeDriverå·²æ›´æ–°åˆ°: {driver_path}")
                return True
            except Exception as e:
                print(f"webdriver-manageræ›´æ–°å¤±è´¥: {e}")
                return False
                
        except Exception as e:
            print(f"å¼ºåˆ¶æ›´æ–°ChromeDriverå¤±è´¥: {e}")
            return False
        
    def init_driver(self, cookies=None):
        """åˆå§‹åŒ–Selenium WebDriver"""
        try:
            chrome_options = Options()
            
            # åŸºæœ¬é€‰é¡¹
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument(f'--user-agent={self.config.USER_AGENT}')
            
            # æ— å¤´æ¨¡å¼
            chrome_options.add_argument('--headless=new')
            
            # å…¼å®¹æ€§é€‰é¡¹
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-plugins')
            chrome_options.add_argument('--no-first-run')
            chrome_options.add_argument('--no-default-browser-check')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-backgrounding-occluded-windows')
            chrome_options.add_argument('--disable-renderer-backgrounding')
            chrome_options.add_argument('--disable-gpu-sandbox')
            chrome_options.add_argument('--disable-software-rasterizer')
            
            # ç½‘ç»œé€‰é¡¹
            chrome_options.add_argument('--ignore-certificate-errors')
            chrome_options.add_argument('--ignore-ssl-errors')
            chrome_options.add_argument('--ignore-certificate-errors-spki-list')
            chrome_options.add_argument('--ignore-ssl-errors-spki-list')
            
            # åæ£€æµ‹é€‰é¡¹
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            # é¡¹ç›®æ ¹ç›®å½•çš„ChromeDriverè·¯å¾„
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            local_chromedriver = os.path.join(project_root, 'chromedriver')
            
            if not os.path.exists(local_chromedriver):
                print(f"æœ¬åœ°ChromeDriverä¸å­˜åœ¨: {local_chromedriver}")
                raise Exception("æœ¬åœ°ChromeDriverä¸å­˜åœ¨")
            
            print(f"æ‰¾åˆ°æœ¬åœ°ChromeDriver: {local_chromedriver}")
            
            # å…ˆå°è¯•æ ‡å‡†Selenium WebDriver
            try:
                print("å°è¯•ä½¿ç”¨æ ‡å‡†Selenium WebDriver...")
                service = Service(local_chromedriver)
                self.driver = webdriver.Chrome(
                    service=service,
                    options=chrome_options
                )
                print("æ ‡å‡†Selenium WebDriveråˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"æ ‡å‡†Seleniumå¤±è´¥: {e}")
                print("å°è¯•ä½¿ç”¨undetected_chromedriver...")
                try:
                    service = Service(local_chromedriver)
                    self.driver = uc.Chrome(
                        service=service,
                        options=chrome_options
                    )
                    print("undetected_chromedriveråˆå§‹åŒ–æˆåŠŸ")
                except Exception as e2:
                    print(f"undetected_chromedriverä¹Ÿå¤±è´¥: {e2}")
                    raise Exception(f"æ‰€æœ‰WebDriveråˆå§‹åŒ–æ–¹æ³•éƒ½å¤±è´¥: {e2}")
            
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.set_page_load_timeout(30)
            self.driver.implicitly_wait(10)
            
            # å¦‚æœæä¾›äº†cookiesï¼Œå…ˆè®¿é—®å°çº¢ä¹¦ä¸»é¡µç„¶åæ·»åŠ cookies
            if cookies:
                try:
                    print("æ­£åœ¨åŠ è½½cookies...")
                    self.driver.get("https://www.xiaohongshu.com")
                    time.sleep(2)
                    
                    # è§£æcookieså­—ç¬¦ä¸²å¹¶æ·»åŠ åˆ°æµè§ˆå™¨
                    if isinstance(cookies, str):
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå°è¯•è§£æ
                        cookie_pairs = cookies.split(';')
                        for pair in cookie_pairs:
                            if '=' in pair:
                                name, value = pair.strip().split('=', 1)
                                try:
                                    self.driver.add_cookie({
                                        'name': name,
                                        'value': value,
                                        'domain': '.xiaohongshu.com'
                                    })
                                except Exception as e:
                                    print(f"æ·»åŠ cookieå¤±è´¥ {name}: {e}")
                    elif isinstance(cookies, list):
                        # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œç›´æ¥æ·»åŠ 
                        for cookie in cookies:
                            try:
                                self.driver.add_cookie(cookie)
                            except Exception as e:
                                print(f"æ·»åŠ cookieå¤±è´¥: {e}")
                    
                    print("cookiesåŠ è½½å®Œæˆ")
                except Exception as e:
                    print(f"åŠ è½½cookiesæ—¶å‡ºé”™: {e}")
            
            print("WebDriveråˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"WebDriveråˆå§‹åŒ–å¤±è´¥: {e}")
            return False
        
    def is_logged_in(self):
        """æ£€æµ‹å½“å‰é¡µé¢æ˜¯å¦å·²ç™»å½•ï¼ˆcookieæ˜¯å¦æœ‰æ•ˆï¼‰"""
        try:
            self.driver.get("https://www.xiaohongshu.com")
            time.sleep(2)
            # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•å¼¹çª—æˆ–æ‰‹æœºå·è¾“å…¥æ¡†
            try:
                # æ£€æŸ¥æ‰‹æœºå·è¾“å…¥æ¡†
                phone_input = self.driver.find_elements(By.XPATH, "//input[@placeholder='è¾“å…¥æ‰‹æœºå·']")
                if phone_input:
                    print("ã€è­¦å‘Šã€‘æ£€æµ‹åˆ°æ‰‹æœºå·è¾“å…¥æ¡†ï¼Œæœªç™»å½•ï¼")
                    return False
                # æ£€æŸ¥ç™»å½•æŒ‰é’®
                login_btn = self.driver.find_elements(By.XPATH, "//button[contains(text(), 'ç™»å½•')]")
                if login_btn:
                    print("ã€è­¦å‘Šã€‘æ£€æµ‹åˆ°ç™»å½•æŒ‰é’®ï¼Œæœªç™»å½•ï¼")
                    return False
                # æ£€æŸ¥äºŒç»´ç ç™»å½•å¼¹çª—
                qr_login = self.driver.find_elements(By.XPATH, "//div[contains(text(), 'ç™»å½•åæŸ¥çœ‹æ›´å¤šæœç´¢ç»“æœ')]")
                if qr_login:
                    print("ã€è­¦å‘Šã€‘æ£€æµ‹åˆ°äºŒç»´ç ç™»å½•å¼¹çª—ï¼Œæœªç™»å½•ï¼")
                    return False
            except Exception as e:
                print(f"ã€è­¦å‘Šã€‘ç™»å½•æ£€æµ‹å¼‚å¸¸: {e}")
            # æ£€æŸ¥å·²ç™»å½•ç‰¹å¾ï¼ˆå¦‚å¤´åƒã€æ¶ˆæ¯ã€å‘å¸ƒæŒ‰é’®ç­‰ï¼‰
            try:
                avatar = self.driver.find_elements(By.CSS_SELECTOR, ".user-avatar, .avatar")
                if avatar:
                    print("æ£€æµ‹åˆ°ç”¨æˆ·å¤´åƒï¼Œå·²ç™»å½•ï¼")
                    return True
            except Exception as e:
                print(f"ã€è­¦å‘Šã€‘å·²ç™»å½•ç‰¹å¾æ£€æµ‹å¼‚å¸¸: {e}")
            # é»˜è®¤æœªç™»å½•
            print("ã€è­¦å‘Šã€‘æœªæ£€æµ‹åˆ°å·²ç™»å½•ç‰¹å¾ï¼Œåˆ¤å®šä¸ºæœªç™»å½•ï¼")
            return False
        except Exception as e:
            print(f"ã€è­¦å‘Šã€‘ç™»å½•æ£€æµ‹ä¸»æµç¨‹å¼‚å¸¸: {e}")
            return False

    def search_notes(self, keyword, limit=20, cookies=None):
        """
        æœç´¢æŒ‡å®šå…³é”®è¯çš„ç¬”è®°
        :param keyword: æœç´¢å…³é”®è¯
        :param limit: è·å–æ•°é‡é™åˆ¶
        :param cookies: å¯é€‰çš„cookieså­—ç¬¦ä¸²
        :return: ç¬”è®°æ•°æ®åˆ—è¡¨
        """
        print(f"ğŸ” å¼€å§‹æœç´¢å…³é”®è¯: {keyword}")
        print(f"ğŸ“Š ç›®æ ‡è·å–æ•°é‡: {limit}")
        
        max_retries = self.config.MAX_RETRIES
        notes_data = []
        
        for attempt in range(max_retries):
            print(f"\nğŸ”„ ç¬¬ {attempt + 1} æ¬¡å°è¯•...")
            
            try:
                # åˆå§‹åŒ–WebDriver
                if not self.init_driver(cookies):
                    print("âŒ WebDriveråˆå§‹åŒ–å¤±è´¥")
                    continue
                
                # æ£€æŸ¥ç™»å½•çŠ¶æ€
                if not self.is_logged_in():
                    print("âŒ æœªç™»å½•æˆ–cookieæ— æ•ˆï¼Œè¯·å…ˆé…ç½®æœ‰æ•ˆçš„Cookie")
                    raise Exception("Cookieæ— æ•ˆæˆ–æœªç™»å½•ï¼Œæ— æ³•è·å–çœŸå®æ•°æ®")
                
                # æ„å»ºæœç´¢URL
                search_url = f"{self.config.XHS_SEARCH_URL}?keyword={keyword}&type=note"
                print(f"ğŸŒ è®¿é—®æœç´¢é¡µé¢: {search_url}")
                
                self.driver.get(search_url)
                time.sleep(random.uniform(3, 5))
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                
                # å°è¯•å¤šä¸ªé€‰æ‹©å™¨æ¥å®šä½ç¬”è®°å…ƒç´ 
                selectors = [
                    "div[data-type='note']",
                    ".note-item",
                    ".search-result-item",
                    "div[class*='note']",
                    "div[class*='item']",
                    "a[href*='/explore/']",
                    ".feed-item"
                ]
                
                note_elements = []
                for selector in selectors:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                            note_elements = elements[:limit]
                            break
                    except Exception as e:
                        print(f"âŒ é€‰æ‹©å™¨ '{selector}' å¤±è´¥: {e}")
                        continue
                
                if not note_elements:
                    print("âš ï¸ æœªæ‰¾åˆ°ç¬”è®°å…ƒç´ ï¼Œå°è¯•æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹...")
                    
                    # æ»šåŠ¨åŠ è½½æ›´å¤šå†…å®¹
                    for i in range(min(3, limit // 5 + 1)):
                        self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                        time.sleep(random.uniform(2, 4))
                        print(f"ğŸ“œ æ»šåŠ¨åŠ è½½ç¬¬ {i+1} æ¬¡")
                    
                    # é‡æ–°è·å–å…ƒç´ 
                    for selector in selectors:
                        try:
                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                            if elements:
                                note_elements = elements[:limit]
                                print(f"âœ… æ»šåŠ¨åæ‰¾åˆ° {len(note_elements)} ä¸ªå…ƒç´ ")
                                break
                        except:
                            continue
                
                # æå–ç¬”è®°æ•°æ®
                for i, element in enumerate(note_elements):
                    try:
                        note_data = self._extract_note_data(element)
                        if note_data:
                            notes_data.append(note_data)
                            print(f"ğŸ“ å·²è·å–ç¬”è®° {i+1}: {note_data.get('title', 'æ— æ ‡é¢˜')}")
                    except Exception as e:
                        print(f"âŒ æå–ç¬”è®° {i+1} æ•°æ®æ—¶å‡ºé”™: {e}")
                        continue
                
                if notes_data:
                    print(f"âœ… æˆåŠŸè·å– {len(notes_data)} æ¡ç¬”è®°")
                    break
                else:
                    print("âš ï¸ æœªè·å–åˆ°ç¬”è®°æ•°æ®")
                    raise Exception("æœªèƒ½ä»é¡µé¢æå–åˆ°ä»»ä½•ç¬”è®°æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–é¡µé¢ç»“æ„")
                    
            except Exception as e:
                print(f"âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                if self.driver:
                    try:
                        self.driver.quit()
                    except:
                        pass
                    self.driver = None
                
                if attempt < max_retries - 1:
                    wait_time = 5 * (attempt + 1)
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
        
        # æ¸…ç†èµ„æº
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass
            self.driver = None
                
        return notes_data

    def _extract_note_data(self, element):
        """ä»ç¬”è®°å…ƒç´ ä¸­æå–æ•°æ®"""
        try:
            # å°è¯•å¤šç§æ–¹å¼æå–æ ‡é¢˜
            title_selectors = [
                ".title", ".note-title", "h3", "h4", 
                "[class*='title']", "[class*='name']",
                "a[href*='/explore/']", ".content"
            ]
            
            title = "æ— æ ‡é¢˜"
            for selector in title_selectors:
                try:
                    title_elem = element.find_element(By.CSS_SELECTOR, selector)
                    title = title_elem.text.strip()
                    if title:
                        break
                except:
                    continue
            
            # å°è¯•å¤šç§æ–¹å¼æå–ä½œè€…
            author_selectors = [
                ".author", ".user-name", ".nickname",
                "[class*='author']", "[class*='user']",
                ".creator", ".publisher"
            ]
            
            author = "æœªçŸ¥ä½œè€…"
            for selector in author_selectors:
                try:
                    author_elem = element.find_element(By.CSS_SELECTOR, selector)
                    author = author_elem.text.strip()
                    if author:
                        break
                except:
                    continue
            
            # å°è¯•å¤šç§æ–¹å¼æå–ç‚¹èµæ•°
            likes_selectors = [
                ".likes", ".like-count", ".count",
                "[class*='like']", "[class*='count']",
                ".interaction", ".stats"
            ]
            
            likes = "0"
            for selector in likes_selectors:
                try:
                    likes_elem = element.find_element(By.CSS_SELECTOR, selector)
                    likes_text = likes_elem.text.strip()
                    # æå–æ•°å­—
                    import re
                    numbers = re.findall(r'\d+', likes_text)
                    if numbers:
                        likes = numbers[0]
                        break
                except:
                    continue
            
            # æå–é“¾æ¥
            link = ""
            try:
                link_elem = element.find_element(By.TAG_NAME, "a")
                link = link_elem.get_attribute("href")
            except:
                try:
                    link = element.get_attribute("href")
                except:
                    pass
            
            # æå–å‘å¸ƒæ—¶é—´
            time_selectors = [
                ".time", ".publish-time", ".date",
                "[class*='time']", "[class*='date']"
            ]
            
            publish_time = ""
            for selector in time_selectors:
                try:
                    time_elem = element.find_element(By.CSS_SELECTOR, selector)
                    publish_time = time_elem.text.strip()
                    if publish_time:
                        break
                except:
                    continue
            
            # æå–å›¾ç‰‡URLï¼ˆå¦‚æœæœ‰ï¼‰
            image_url = ""
            try:
                img_elem = element.find_element(By.TAG_NAME, "img")
                image_url = img_elem.get_attribute("src")
            except:
                pass
            
            return {
                'title': title,
                'author': author,
                'likes': likes,
                'link': link,
                'publish_time': publish_time,
                'image_url': image_url,
                'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            print(f"âŒ æå–ç¬”è®°æ•°æ®æ—¶å‡ºé”™: {e}")
            return None

    def _create_mock_data(self, keyword, limit):
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼ˆå·²ç¦ç”¨ - åªè·å–çœŸå®æ•°æ®ï¼‰"""
        raise Exception("æ¨¡æ‹Ÿæ•°æ®åŠŸèƒ½å·²ç¦ç”¨ï¼Œè¯·é…ç½®æœ‰æ•ˆçš„Cookieè·å–çœŸå®æ•°æ®")
    
    def save_to_csv(self, data, filename=None):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        if not filename:
            filename = f"xhs_notes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.config.DATA_DIR, exist_ok=True)
        filepath = os.path.join(self.config.DATA_DIR, filename)
        
        df = pd.DataFrame(data)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        print(f"æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def crawl_hot_notes(self, topic, limit=20, cookies=None):
        """
        çˆ¬å–æŒ‡å®šä¸»é¢˜çš„çƒ­é—¨ç¬”è®°
        :param topic: ä¸»é¢˜å…³é”®è¯
        :param limit: è·å–æ•°é‡
        :param cookies: å¯é€‰çš„cookieså­—ç¬¦ä¸²
        :return: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print(f"å¼€å§‹çˆ¬å–ä¸»é¢˜ '{topic}' çš„çƒ­é—¨ç¬”è®°...")
        notes_data = self.search_notes(topic, limit, cookies)
        
        if notes_data:
            filename = f"xhs_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            filepath = self.save_to_csv(notes_data, filename)
            print(f"æˆåŠŸçˆ¬å– {len(notes_data)} æ¡ç¬”è®°")
            return filepath
        else:
            print("æœªè·å–åˆ°ä»»ä½•ç¬”è®°æ•°æ®")
            return None

if __name__ == "__main__":
    # æµ‹è¯•çˆ¬è™«
    crawler = XHSCrawler()
    result = crawler.crawl_hot_notes("ç¾é£Ÿ", 10)
    print(f"çˆ¬å–ç»“æœ: {result}") 